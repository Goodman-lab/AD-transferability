{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ebc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created Aug 2021\n",
    "\n",
    "Author: Marcus Wei How Wang\n",
    "Code available at: https://github.com/Goodman-lab/AD-transferability\n",
    "Please acknowledge the authors if using the code, whether partially or in full\n",
    "\"\"\"\n",    
    "# For use with model vs other targets from Tim's code\n",
    "# LATEST CODE UPDATED Aug 2021\n",
    "# Code for calculating applicability domain metric based on Tanimoto similarity\n",
    "\n",
    "# Note google colab disconnects and clears data after 12 hrs of inactivity\n",
    "# But code still runs in the background even if runtime is disconnected before the 12hr mark\n",
    "\n",
    "# Relevant imports\n",
    "import numpy as np\n",
    "import pandas as pd # uses pandas python module to view and analyse data\n",
    "\n",
    "import time\n",
    "from time import strftime, gmtime\n",
    "\n",
    "import os\n",
    "from os import mkdir\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "from rdkit.Chem import rdqueries\n",
    "\n",
    "from rdkit import DataStructs\n",
    "\n",
    "import requests\n",
    "import random\n",
    "\n",
    "!pip install chembl_webresource_client\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "\n",
    "#=======================================================================================#\n",
    "\n",
    "#====================================================================================#\n",
    "# Get list of random numbers\n",
    "# Function to generate list of random integers with a specified number of elements in list\n",
    "\n",
    "# random.randint(0,1) generates a random integer between 0 and 1 inclusive\n",
    "def random_list(start,end,quota):\n",
    "    rand_ls = []\n",
    "    rand_ls.clear()\n",
    "\n",
    "    while len(rand_ls) < quota:    \n",
    "        rand_ls.append(random.randint(start,end))\n",
    "        rand_ls = list(set(rand_ls))\n",
    "\n",
    "    return rand_ls\n",
    "\n",
    "def empty_list_check(ls):\n",
    "    if len(ls) != 0:\n",
    "        return ls\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Function to get list of smiles and inchis given search property\n",
    "def ChEMBL_get(ChEMBL_CID_ls):\n",
    "    molecule = new_client.molecule\n",
    "    smiles_ls = []\n",
    "    smiles_ls.clear()\n",
    "\n",
    "    records = molecule.get(ChEMBL_CID_ls)\n",
    "    for ele in records:\n",
    "        try:\n",
    "            temp = ele['molecule_structures']\n",
    "            temp2 = temp['canonical_smiles']\n",
    "            smiles_ls.append(temp2)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return smiles_ls\n",
    "    \n",
    "def Timecheck():\n",
    "    start_time = strftime(\"%H:%M:%S\", gmtime())\n",
    "    print('\\nCurrent time:')\n",
    "    print(start_time)\n",
    "    return\n",
    "\n",
    "def Timer(start_time,end_time):\n",
    "    hr, mod = divmod(end_time - start_time, 3600)\n",
    "    min, sec = divmod(mod, 60)\n",
    "    output = \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hr),int(min),int(sec))\n",
    "    output = str(output)\n",
    "\n",
    "    return output\n",
    "#====================================================================================#\n",
    "# Fingerprint code from usual place from Tim's paper\n",
    "def get_fingerprint(smiles):\n",
    "    '''smiles dataframe'''\n",
    "    rdkit_molecules=[Chem.MolFromSmiles(x) for x in smiles['Smiles']]\n",
    "    rdkit_fingerprint=[]\n",
    "    count = 0\n",
    "    for mol in rdkit_molecules:\n",
    "        # if count % 1000 == 0:\n",
    "        #     print('Now fingerprinting {} of {}'.format(count,len(rdkit_molecules)))\n",
    "        bit_info={}\n",
    "        fp=rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=fingerprint_radius, nBits=fingerprint_length, \\\n",
    "                                                                      bitInfo=bit_info)\n",
    "        \n",
    "        rdkit_fingerprint.append(fp)\n",
    "        count += 1\n",
    "        \n",
    "    #fingerprint_df=pd.DataFrame([np.array(list(x)).astype(int) for x in rdkit_fingerprint])\n",
    "    fingerprint_df = pd.DataFrame(rdkit_fingerprint,columns=['BV'])\n",
    "    \n",
    "    return fingerprint_df\n",
    "\n",
    "def CreateBitString(df,nBits):\n",
    "    # Combine all columns with fingerprint values into format suitable for bitvector processing\n",
    "    fp = df.iloc[:,0:nBits]\n",
    "    fp['combined'] = fp[fp.columns.tolist()].apply(lambda row: ''.join(row.values.astype(str)), axis=1)\n",
    "    fp = fp[['combined']]\n",
    "\n",
    "    return fp\n",
    "\n",
    "def CreateBitVect(df):\n",
    "    #print('\\nCreateBitVect')\n",
    "\n",
    "    df['BV'] = df.apply(lambda row : DataStructs.CreateFromBitString(row['combined']), axis = 1)\n",
    "    df = df[['BV']]\n",
    "    return df\n",
    "\n",
    "def carbon_atom_check(smiles):\n",
    "    # Check no. of C atoms\n",
    "    query = rdqueries.AtomNumEqualsQueryAtom(6)\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles) \n",
    "    check = len(mol.GetAtomsMatchingQuery(query))\n",
    "\n",
    "    return check\n",
    "\n",
    "\n",
    "def Smiles_Checker(df):\n",
    "    error_ls = []\n",
    "    error_ls.clear()\n",
    "\n",
    "    for x in range(0,len(df)):\n",
    "        query = df.iloc[x]['Smiles']\n",
    "        # List of meetals to remove because rdkit doesn't do it well enough\n",
    "        # Check for metals and remove if necessary\n",
    "        check_ls = ['Hg','Pb','He','Li','Be','Ne','Na','Mg','Al','Ar','K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn','Ga','Kr','Rb','Se',\n",
    "                'Sr','Y','Zr','Nb','Mo','Tc','Ru','Rh','Pd','Pt','Ag','Au','Cd','In','Sn','Xe','Cs','Ba','La','Sb','Te','Os','Ir','As','Ge']\n",
    "\n",
    "        if any(ele in query for ele in check_ls) == True:\n",
    "            error_ls.append(x)\n",
    "            continue\n",
    "\n",
    "        # Check for salts and remove if necessary\n",
    "        try:\n",
    "            remover = SaltRemover()\n",
    "            mol = Chem.MolFromSmiles(query)\n",
    "            res = remover.StripMol(mol,dontRemoveEverything=True)\n",
    "            update = Chem.MolToSmiles(res)\n",
    "            query = update\n",
    "        except:\n",
    "            error_ls.append(x)\n",
    "            continue\n",
    "\n",
    "        # Check for at least one carbon atom since we want organics\n",
    "        check = carbon_atom_check(query)\n",
    "\n",
    "        # Has carbon atom ie. check != 0\n",
    "        if check == 0:\n",
    "            error_ls.append(x)\n",
    "            continue\n",
    "\n",
    "    # After performing all 3 checks per smiles in df and dropping if necessary\n",
    "    # If all three checks passed, df will contain 2 smiles, else less than 2\n",
    "    df = df.drop(error_ls)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def Min_df_check(df1,df2):\n",
    "    if len(df1) < len(df2):\n",
    "        return len(df1)\n",
    "    if len(df1) > len(df2):\n",
    "        return len(df2)\n",
    "    else:   # If both dfs are equal\n",
    "        return len(df1)\n",
    "\n",
    "def quota_loop(df):\n",
    "\n",
    "    while len(df) != quota:\n",
    "        Timecheck()\n",
    "\n",
    "        smiles_to_get = quota - len(df)\n",
    "        print('\\ndf NOW CONTAINS {} SMILES'.format(len(df)))\n",
    "\n",
    "        if quota <= 100:\n",
    "            ChEMBL_CID_ls = list(np.random.randint(low=1, high=2000000, size=(smiles_to_get)))\n",
    "\n",
    "        if quota > 100:\n",
    "            check_count = quota - len(df)\n",
    "            if check_count <= 100: \n",
    "                ChEMBL_CID_ls = list(np.random.randint(low=1, high=2000000, size=check_count))\n",
    "            if check_count > 100:\n",
    "                ChEMBL_CID_ls = list(np.random.randint(low=1, high=2000000, size=100))\n",
    "\n",
    "        for x in range(0,len(ChEMBL_CID_ls)):\n",
    "            ChEMBL_CID_ls[x] = 'CHEMBL' + str(ChEMBL_CID_ls[x])\n",
    "\n",
    "        smiles_ls_update = ChEMBL_get(ChEMBL_CID_ls)\n",
    "        if len(smiles_ls_update) != 0:\n",
    "            smiles_df_update = pd.DataFrame(smiles_ls_update, columns=['Smiles'])\n",
    "            smiles_df_update = Smiles_Checker(smiles_df_update)\n",
    "\n",
    "            df = pd.concat([df,smiles_df_update],axis=0)\n",
    "            df = df.drop_duplicates(subset='Smiles',keep='first')\n",
    "            df = df.reset_index(drop=True)\n",
    "            \n",
    "    return df\n",
    "#===================================================================================================#\n",
    "# Define some more functions\n",
    "\n",
    "# Function splits a df into actives and inactives and returns two dfs\n",
    "def active_inactive_split(df):\n",
    "    #print('\\nactive_inactive_split CALLED')\n",
    "\n",
    "    active_index = []\n",
    "    active_index.clear()\n",
    "\n",
    "    # Get index of actives\n",
    "    temp = df.iloc[:,-2:]   # This will get SMILES column and activity column\n",
    "    temp_df = df\n",
    "    for x in range(0,len(temp)):\n",
    "        if temp.iloc[x]['Binary Activity'] == 1:\n",
    "            active_index.append(x)\n",
    "    \n",
    "    # Seperate actives and inactives intwo two dfs\n",
    "    #print('\\nCREATING ACTIVE DF...')\n",
    "    active_df = temp_df.iloc[active_index]    \n",
    "    active_df = active_df.reset_index(drop=True)\n",
    "\n",
    "    #print('\\nCREATING INACTIVE DF...')\n",
    "    inactive_df = df.drop(df.index[[active_index]])\n",
    "    inactive_df = inactive_df.reset_index(drop=True)\n",
    "    \n",
    "    return active_df, inactive_df\n",
    "\n",
    "\n",
    "def Calc_Similarity(bv1,bv2,process,allsim):    # allsim defines whether to calculate for all similarity pairs\n",
    "    #print('\\nCalc_Similarity CALLED')\n",
    "    # Calculate Tanimoto similarity between both samples\n",
    "    output_dict = {}\n",
    "    \n",
    "    output_ls = []\n",
    "    output_ls.clear()\n",
    "\n",
    "    output_ls2 = []\n",
    "    output_ls2.clear()\n",
    "\n",
    "    output_ls3 = []\n",
    "    output_ls3.clear()  \n",
    "\n",
    "    output_ls4 = []\n",
    "    output_ls4.clear()    \n",
    "\n",
    "    output_ls5 = []\n",
    "    output_ls5.clear()      \n",
    "\n",
    "    sim_count = 0    \n",
    "\n",
    "    for x in range(0,len(bv1)):\n",
    "        check = 0\n",
    "        bv1_bv = bv1.iloc[x]['BV']\n",
    "\n",
    "        if x % 500 == 0:\n",
    "            print ('Current time:')\n",
    "            print(strftime(\"%H:%M:%S\", gmtime()))\n",
    "            print('NOW CALCULATING SIMILARITIES FOR PROCESS {} INDEX {}'.format(process,x))\n",
    "\n",
    "        for y in range(0,len(bv2)):\n",
    "\n",
    "            bv2_bv = bv2.iloc[y]['BV']\n",
    "            sim = DataStructs.TanimotoSimilarity(bv1_bv,bv2_bv)\n",
    "            output_ls.append(sim)\n",
    "            output_ls2.append(x)\n",
    "            output_ls3.append(y)\n",
    "#             if process == 1:\n",
    "#                 output_ls4.append(AOP_smiles.iloc[x]['SMILES'])\n",
    "#                 output_ls5.append(target_smiles.iloc[y]['SMILES'])\n",
    "#             else:\n",
    "#                 output_ls4.append(target_smiles.iloc[x]['SMILES'])\n",
    "#                 output_ls5.append(AOP_smiles.iloc[y]['SMILES'])\n",
    "\n",
    "            # Process sim per molecule and determine if molecule is similar to second dataset                            \n",
    "            if check == 0:\n",
    "                if sim >= T_sim_threshold and allsim == 1: \n",
    "                    sim_count += 1\n",
    "                    check += 1\n",
    "                if sim >= T_sim_threshold and allsim == 0: \n",
    "                    sim_count += 1\n",
    "                    check += 1\n",
    "                    break              \n",
    "    \n",
    "    #print('\\nTANIMOTO SIMILARITIES CALCULATED')\n",
    "    # Put all required values into dictionary\n",
    "    output_dict['sim_count'] = sim_count\n",
    "    output_dict['output_ls'] = output_ls\n",
    "    output_dict['bv1_index'] = output_ls2\n",
    "    output_dict['bv2_index'] = output_ls3\n",
    "#     output_dict['AOP SMILES'] = output_ls4\n",
    "#     output_dict['Target SMILES'] = output_ls5\n",
    "    #print(output_dict.get('sim_count'))\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "def Remove_Unnamed(df):\n",
    "    try:\n",
    "        df = df.drop(['Unnamed: 0'],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return df\n",
    "#===================================================================================================#\n",
    "\n",
    "#===================================================================================================#\n",
    "# Start main code\n",
    "\n",
    "sim_ls = []\n",
    "sim_ls.clear()\n",
    "\n",
    "mol_threshold_ls = []\n",
    "mol_threshold_ls.clear()\n",
    "\n",
    "temp_ls = []\n",
    "temp_ls.clear()\n",
    "\n",
    "# READ REQUIRED FILES\n",
    "print('\\nSETTING UP TARGETS...')\n",
    "\n",
    "# Set up targets using Tim's data\n",
    "# Read csv file containing targets to calculate\n",
    "filename = 'C:/Users/mwhw3/Desktop/AOP project/Input data/'\n",
    "filename = filename + 'Targets to calculate 5.csv'\n",
    "\n",
    "target_df = pd.read_csv(filename)\n",
    "target_df = target_df[['Target']]\n",
    "print(target_df)\n",
    "\n",
    "#====================================================================================#\n",
    "nBits = 2048\n",
    "length = nBits\n",
    "fingerprint_length = nBits\n",
    "quota = 10000\n",
    "sample_ls = [1,2,3]\n",
    "file_active = 0\n",
    "fingerprint_radius = 2\n",
    "\n",
    "for sample in sample_ls:\n",
    "    # Set up initial df\n",
    "    print('\\nSETTING UP ChEMBL DF1...')\n",
    "    start_time = time.time()\n",
    "    Timecheck()\n",
    "    if quota <= 100:\n",
    "        ChEMBL_CID_ls = list(np.random.randint(low=1, high=2000000, size=(quota)))\n",
    "\n",
    "    if quota > 100:\n",
    "        ChEMBL_CID_ls = list(np.random.randint(low=1, high=2000000, size=(100)))\n",
    "\n",
    "    for x in range(0,len(ChEMBL_CID_ls)):\n",
    "        ChEMBL_CID_ls[x] = 'CHEMBL' + str(ChEMBL_CID_ls[x])\n",
    "\n",
    "    smiles_ls = ChEMBL_get(ChEMBL_CID_ls)\n",
    "    if len(smiles_ls) != 0:\n",
    "        smiles_df1 = pd.DataFrame(smiles_ls, columns=['Smiles'])\n",
    "        smiles_df1 = Smiles_Checker(smiles_df1)\n",
    "\n",
    "    # Repeat random generation until quota is reached\n",
    "    smiles_df1 = quota_loop(smiles_df1)\n",
    "\n",
    "    print(smiles_df1)\n",
    "    Timecheck()\n",
    "\n",
    "    print('\\nChEMBL DF1 SET UP')\n",
    "\n",
    "    # Save file containing smiles \n",
    "    root_dir = 'C:/Users/mwhw3/Desktop/AOP project/ChEMBL smiles/'\n",
    "    filename = root_dir + str(quota) + ' ChEMBL smiles_' + str(nBits) + ' bits_sample ' + str(sample) + '.csv'\n",
    "    smiles_df1.to_csv(filename)\n",
    "\n",
    "    #====================================================================================#\n",
    "    # Converting smiles to fingerprints\n",
    "    training_df = get_fingerprint(smiles_df1)\n",
    "\n",
    "    print(training_df)\n",
    "\n",
    "    #===================================================================================================#\n",
    "    print ('Current time:')\n",
    "    print(strftime(\"%H:%M:%S\", gmtime())) \n",
    "\n",
    "    target_count = 0\n",
    "    train_inactive_bv_df = training_df\n",
    "\n",
    "    print (train_inactive_bv_df.shape)\n",
    "\n",
    "    initial = 0\n",
    "\n",
    "    for protein in range(initial,len(target_df)):\n",
    "\n",
    "        T_ls = [0.3]\n",
    "        nBits = 2048\n",
    "\n",
    "        target = str(target_df.loc[protein]['Target'])\n",
    "\n",
    "        print('Processing target: {}'.format(protein))\n",
    "        print('Processing target: {}'.format(target))\n",
    "\n",
    "        # Read file 2 (test dataset)\n",
    "        print ('\\nReading file 2...')\n",
    "        print ('Current time:')\n",
    "        print(strftime(\"%H:%M:%S\", gmtime())) \n",
    "        start = time.time()\n",
    "\n",
    "        filename = 'C:/Users/mwhw3/Desktop/AOP project/Input data/'\n",
    "        filename = filename + str(target) + '_train_fingerprints Morgan ' + str(length) + '.csv'\n",
    "        test_fp_df = pd.read_csv(filename)\n",
    "        test_fp_df = Remove_Unnamed(test_fp_df)\n",
    "\n",
    "        test_fp_df = test_fp_df.reset_index(drop=True)\n",
    "\n",
    "        print (test_fp_df.shape)\n",
    "\n",
    "        # Split training data into actives and inactives\n",
    "        test_active, test_inactive = active_inactive_split(test_fp_df)\n",
    "        if file_active == 0:    # Lazy man way of choosing inactives without replacing code\n",
    "            test_active = test_inactive\n",
    "\n",
    "        target_smiles = test_active[['SMILES']]\n",
    "        print(target_smiles)\n",
    "        test_active = test_active.drop(['SMILES'],axis=1)\n",
    "\n",
    "        # Drop Binary activity column\n",
    "        test_active = test_active.iloc[:, :-1]\n",
    "        print(test_active)\n",
    "\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        minutes = elapsed // 60\n",
    "        seconds = elapsed - (minutes*60)\n",
    "        print('File 2 took {} minutes and {} seconds to read'.format(minutes,seconds))\n",
    "\n",
    "        #=========================================================================================#\n",
    "\n",
    "        print('\\nCREATING BITVECT DFs FOR TEST DATA...')\n",
    "        test_active_fp = CreateBitString(test_active,2048)\n",
    "        test_active_bv_df = CreateBitVect(test_active_fp)\n",
    "        # test_inactive_bv_df = CreateBitVect(test_inactive_fp)\n",
    "\n",
    "        print('\\nTEST BITVECT DFs CREATED')\n",
    "        #=========================================================================================#\n",
    "\n",
    "        # Caclulate Tanimoto similarities\n",
    "        # Slow process\n",
    "        print('\\nCALCULATING TANIMOTO SIMILARITIES...')\n",
    "\n",
    "        # Set similarity threshold\n",
    "\n",
    "        sim_ls = []\n",
    "        sim_ls.clear()\n",
    "\n",
    "        temp_ls = []\n",
    "        temp_ls.clear()\n",
    "\n",
    "        T_sim_threshold = float(T_ls[0])\n",
    "\n",
    "        print('\\nNOW CALCULATING FOR THRESHOLD: {}'.format(T_sim_threshold))\n",
    "        print('\\nNOW CALCULATING FOR TARGET: {}'.format(target))\n",
    "\n",
    "        indicator_ls = []\n",
    "        indicator_ls.clear()\n",
    "\n",
    "        train_count_ls = []\n",
    "        train_count_ls.clear()\n",
    "\n",
    "        test_count_ls = []\n",
    "        test_count_ls.clear()\n",
    "\n",
    "        # Ensure that training bv df is followed by teste bv df for train sim indicator\n",
    "        # Ensure that actives are matched with actives and vice versa\n",
    "        # Start multiprocessing and queues\n",
    "        start = time.time()\n",
    "\n",
    "        temp_dict1 = Calc_Similarity(train_inactive_bv_df,test_active_bv_df,1,1)\n",
    "        temp_dict2 = Calc_Similarity(test_active_bv_df,train_inactive_bv_df,2,0) \n",
    "        print('\\nSIMILARITY CALCULATIONS FINISHED')\n",
    "        # Get sim_count for training with test\n",
    "        temp_count1 = temp_dict1.get('sim_count')\n",
    "        temp_count2 = temp_dict2.get('sim_count')\n",
    "\n",
    "        temp_ls1 = temp_dict1.get('output_ls')\n",
    "        temp_ls2 = temp_dict2.get('output_ls')\n",
    "\n",
    "        temp_ls3 = temp_dict1.get('bv1_index')\n",
    "        temp_ls4 = temp_dict1.get('bv2_index')\n",
    "\n",
    "        temp_ls5 = temp_dict2.get('bv1_index')\n",
    "        temp_ls6 = temp_dict2.get('bv2_index')\n",
    "\n",
    "        temp_ls7 = temp_dict1.get('AOP SMILES')\n",
    "        temp_ls8 = temp_dict1.get('Target SMILES') \n",
    "\n",
    "        temp_ls9 = temp_dict2.get('AOP SMILES')\n",
    "        temp_ls10 = temp_dict2.get('Target SMILES')            \n",
    "\n",
    "        sim_count = temp_count1 + temp_count2\n",
    "\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        minutes = elapsed // 60\n",
    "        seconds = elapsed - (minutes*60)\n",
    "\n",
    "        print('\\n#=====================================================================#')\n",
    "        print('\\n#=====================================================================#')\n",
    "        print('\\nTRAINING AND TEST TANIMOTO SIMILARITIES CALCULATED')\n",
    "        print('Code took {} minutes and {} seconds'.format(minutes,seconds))\n",
    "        print('\\n#=====================================================================#')\n",
    "        print('\\n#=====================================================================#')\n",
    "\n",
    "        #=========================================================================================#\n",
    "        print('\\nCALCULATING TRAINING SIMILARITY INDICATOR...')\n",
    "\n",
    "        train_indicator = temp_count1 / (len(train_inactive_bv_df)) * 100\n",
    "        indicator_ls.append(train_indicator)\n",
    "\n",
    "        print('\\nTRAINING SIMILARITY INDICATOR CALCULATED')\n",
    "        #=========================================================================================#\n",
    "\n",
    "        print('\\nCALCULATING TEST SIMILARITY INDICATOR...')\n",
    "\n",
    "        test_indicator =  temp_count2 / (len(test_active_bv_df)) * 100\n",
    "        indicator_ls.append(test_indicator)\n",
    "\n",
    "        print('\\nTEST SIMILARITY INDICATOR CALCULATED')\n",
    "\n",
    "        #=========================================================================================#\n",
    "        print('\\nCALCULATING AVERAGE SIMILARITY INDICATOR...')\n",
    "\n",
    "        average_indicator = (train_indicator + test_indicator) / 2\n",
    "        indicator_ls.append(average_indicator)\n",
    "\n",
    "        indicator_df = pd.DataFrame(indicator_ls).T\n",
    "        indicator_df.columns = ['Train','Test','Average']\n",
    "\n",
    "        print(indicator_df)\n",
    "\n",
    "        print('\\nAVERAGE SIMILARITY INDICATOR CALCULATED')\n",
    "\n",
    "        #=========================================================================================#\n",
    "\n",
    "        # Append data counts in dfs\n",
    "        train_count_ls.append((len(train_inactive_bv_df)))\n",
    "        test_count_ls.append((len(test_active_bv_df)))\n",
    "        sim_ls.append(T_sim_threshold)\n",
    "        temp_ls.append(target)\n",
    "\n",
    "        #=========================================================================================#\n",
    "        # Collate all files/results\n",
    "        # Quick process\n",
    "\n",
    "        combined_df = indicator_df\n",
    "\n",
    "        combined_df['Sim'] = sim_ls\n",
    "        combined_df['Target'] = temp_ls\n",
    "        combined_df['train_target count'] = train_count_ls\n",
    "        combined_df['test_target count'] = test_count_ls\n",
    "        print(combined_df)\n",
    "\n",
    "        #===========================================================================#\n",
    "        # Process df and save\n",
    "\n",
    "        print('\\nSAVING DF FOR TARGET {}'.format(protein))\n",
    "        print ('\\nSAVING FILES...')\n",
    "\n",
    "        if protein == 0:\n",
    "            all_df = combined_df\n",
    "        else:\n",
    "            all_df = pd.concat([all_df,combined_df],axis=0)\n",
    "            all_df = all_df.reset_index(drop=True)\n",
    "\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        minutes = elapsed // 60\n",
    "        seconds = elapsed - (minutes*60)\n",
    "\n",
    "        print ('\\n#=========================================================================#')\n",
    "\n",
    "        # Save all_df in separate easy to access folder (combined df with all calculated targets for easy copying)\n",
    "        root_dir = 'C:/Users/mwhw3/Desktop/AOP project/Similarity results/'\n",
    "\n",
    "        if file_active == 0:\n",
    "            filename = root_dir + 'all_df_quota ' + str(quota) + '_sample '+ str(sample) + '_ChEMBLinactivedata_indicator'   \n",
    "        if file_active == 1:  \n",
    "            filename = root_dir + 'all_df_quota ' + str(quota) + '_sample '+ str(sample) + '_ChEMBLactivedata_indicator'    \n",
    "\n",
    "        filename = filename + str(nBits) + 'bits_' + str(T_sim_threshold) + 'T_threshold.csv'\n",
    "        all_df.to_csv(filename)\n",
    "        print('\\nALL RESULTS FILE SAVED')\n",
    "\n",
    "\n",
    "print('\\nFINISHED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
